{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with TF, following examples on the web\n",
    "Mostly from the project tensorflow_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A namedtuple can be used for storing hyper-params\n",
    "It generates a class which its instances can return tuples, but fields can be referred by name. However, it would not work well with take_from_struct style params. So it would better be using a dictionary and fetching default values if a param doesnt exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperParams(lr=0.1, w_decay=0.001)\n",
      "0.1 0.001\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "HyperParams = namedtuple('HyperParams', 'lr, w_decay')\n",
    "hp = HyperParams(lr=0.1, w_decay=1e-3)\n",
    "print hp\n",
    "a,b=hp\n",
    "print a,b\n",
    "print hp.lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threads and queues\n",
    "[link](https://www.tensorflow.org/versions/r0.10/how_tos/threading_and_queues/index.html)\n",
    "A **queue is a node** in a TensorFlow graph. It's a stateful node, like a variable: other nodes can modify its content. In particular, nodes can enqueue new items in to the queue, or dequeue existing items from the queue.\n",
    "\n",
    "A simple example: A \"first in, first out\" queue (FIFOQueue) init it with zeros. Then we'll construct a graph that takes an item off the queue, adds one to that item, and puts it back on the end of the queue. Slowly, the numbers on the queue increase.\n",
    "\n",
    "![](https://www.tensorflow.org/versions/r0.10/images/IncremeterFifoQueue.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinator\n",
    "[link](https://www.tensorflow.org/versions/r0.10/how_tos/threading_and_queues/index.html#Coordinator)\n",
    "\n",
    "### QueueRunner\n",
    "\n",
    "The QueueRunner class creates a number of threads that repeatedly run an enqueue op. These threads can use a coordinator to stop together. In addition, a queue runner runs a closer thread that automatically closes the queue if an exception is reported to the coordinator.\n",
    "\n",
    "**Implementation:** First **build a graph** with **a Queue for input examples**. Add **ops** that **process examples** and **enqueue them** in the queue. Add **training ops** that start by **dequeueing** from the queue\n",
    "\n",
    "    example = ...ops to create one example...\n",
    "    # Create a queue, and an op that enqueues examples one at a time in the queue.\n",
    "    queue = tf.RandomShuffleQueue(...)\n",
    "    enqueue_op = queue.enqueue(example)\n",
    "    # Create a training graph that starts by dequeuing a batch of examples.\n",
    "    inputs = queue.dequeue_many(batch_size)\n",
    "    train_op = ...use 'inputs' to build the training part of the graph...\n",
    "\n",
    "\n",
    "In the Python **training program**, create a **QueueRunner** that will **run threads** to process and enqueue examples. Create a Coordinator and **ask the queue runner to start its threads with the coordinator**. Write a training loop that also uses the coordinator.\n",
    "\n",
    "    # Create a queue runner that will run 4 threads in parallel to enqueue\n",
    "    # examples.\n",
    "    qr = tf.train.QueueRunner(queue, [enqueue_op] * 4)\n",
    "\n",
    "    # Launch the graph.\n",
    "    sess = tf.Session()\n",
    "    # Create a coordinator, launch the queue runner threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    # Run the training loop, controlling termination with the coordinator.\n",
    "    for step in xrange(1000000):\n",
    "        if coord.should_stop():\n",
    "            break\n",
    "        sess.run(train_op)\n",
    "    # When done, ask the threads to stop.\n",
    "    coord.request_stop()\n",
    "    # And wait for them to actually do it.\n",
    "    coord.join(enqueue_threads)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reader and queues  for input pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TF pipeline supports reading data from multiple files (possibly with multiple threads), preprocessing it on the fly and feedining it as batches for training. This pipeline involves 3 queues that are piped.\n",
    "\n",
    "#### Here is an illustration\n",
    "![](https://www.tensorflow.org/versions/r0.10/images/AnimatedFileQueues.gif)\n",
    "\n",
    "#### Here is a TL;DR from the TF (`QueueRunner`) tutorial\n",
    "One set of threads generates filenames in a queue; a second set of threads read records from the files, processes them, and enqueues tensors on a second queue; a third set of threads (not shown in animation) dequeues these input records to construct batches and runs them through training operations.\n",
    "\n",
    "#### In more details\n",
    "Many of the `tf.train` functions listed above add `QueueRunner` objects to your graph. These require that you call `tf.train.start_queue_runners` before running any training or inference steps, or it will hang forever. This will start threads that run the input pipeline, filling the example queue so that the dequeue to get the examples will succeed. This is best combined with a `tf.train.Coordinator` to cleanly shut down these threads when there are errors. If you set a limit on the number of epochs, that will use an epoch counter that will need to be initialized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
