{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with TF, following examples on the web\n",
    "Mostly from the project tensorflow_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A namedtuple can be used for storing hyper-params\n",
    "It generates a class which its instances can return tuples, but fields can be referred by name. However, it would not work well with take_from_struct style params. So it would better be using a dictionary and fetching default values if a param doesnt exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperParams(lr=0.1, w_decay=0.001)\n",
      "0.1 0.001\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "HyperParams = namedtuple('HyperParams', 'lr, w_decay')\n",
    "hp = HyperParams(lr=0.1, w_decay=1e-3)\n",
    "print hp\n",
    "a,b=hp\n",
    "print a,b\n",
    "print hp.lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reader and queues  for input pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TF pipeline supports reading data from multiple files (possibly with multiple threads), preprocessing it on the fly and feedining it as batches for training. This pipeline involves 3 queues that are piped.\n",
    "\n",
    "#### Here is an illustration\n",
    "![](https://www.tensorflow.org/versions/r0.10/images/AnimatedFileQueues.gif)\n",
    "\n",
    "#### Here is a TL;DR from the TF (`QueueRunner`) tutorial\n",
    "One set of threads generates filenames in a queue; a second set of threads read records from the files, processes them, and enqueues tensors on a second queue; a third set of threads dequeues these input records to construct batches and runs them through training operations.\n",
    "\n",
    "#### In more details\n",
    "Many of the `tf.train` functions listed above add `QueueRunner` objects to your graph. These require that you call `tf.train.start_queue_runners` before running any training or inference steps, or it will hang forever. This will start threads that run the input pipeline, filling the example queue so that the dequeue to get the examples will succeed. This is best combined with a `tf.train.Coordinator` to cleanly shut down these threads when there are errors. If you set a limit on the number of epochs, that will use an epoch counter that will need to be initialized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
