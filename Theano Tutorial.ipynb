{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every **row** is an example, every **column** is a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 3.  4.]\n",
      " [ 5.  6.]]\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# A np matrix\n",
    "A = numpy.asarray([[1., 2], [3, 4], [5, 6]])\n",
    "print A\n",
    "# access a specific element\n",
    "print A[2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np Broadcasting\n",
    "The smaller array (or scalar) is broadcasted across the larger array so that they\n",
    "have compatible shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  4.,  6.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = numpy.asarray([1.0, 2.0, 3.0])\n",
    "b=2\n",
    "a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano Baby Steps\n",
    "Let's make a simple function: add two numbers together\n",
    "\n",
    "From now on, we will use *Variable* to mean *symbol*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import theano.tensor as T\n",
    "from theano import function\n",
    "x = T.dscalar('x') # variable (symbol)\n",
    "y = T.dscalar('y') # variable (symbol)\n",
    "z = x + y # z is a Variable which represents addition of x and y\n",
    "f = function([x, y], z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theano flags\n",
    "THEANO_FLAGS='device=gpu0,floatX=float32,blas.ldflags=\"-L/usr/lib/ -lblas\"'\n",
    "\n",
    "#### With debugging\n",
    "THEANO_FLAGS='device=gpu0,floatX=float32,exception_verbosity=high,optimizer=None,blas.ldflags=\"-L/usr/lib/ -lblas\"'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pretty Print !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x + y)\n"
     ]
    }
   ],
   "source": [
    "from theano import pp\n",
    "print pp(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Theano function\n",
    "*First argument* is a list of input Variables. *The second* is a single (or list of) Variable(s). The ** second** argument **is what we want to see as output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(5.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eval fun\n",
    "f(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.allclose(f(16.3, 12.1), 28.4+1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*dscalar* is **not a class**. Therefore, x and y are not instances of dscalar. **x and y are instances of TensorVariable**\n",
    "Names are not required, but they can help debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A side note: using `eval` instead of `function`\n",
    "As a (typing) shortcut, you can just use a variable's eval method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.allclose(z.eval({x : 16.3, y : 12.1}), 28.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding matrices, is similar\n",
    "Using `x = T.dmatrix('x')` instead of `T.dscalar('x')`\n",
    "#### Broadcating:\n",
    "Using broadcasting, it is possible to add scalars to matrices, vectors to matrices, scalars to vectors, etc.\n",
    "#### Many types are available.\n",
    "E.g. `fscalar, fvector, fmatrix, frow, fcol, ftensor3, ftensor4`\n",
    "See also [Basic Tensor Functionality](http://deeplearning.net/software/theano/library/tensor/basic.html#libdoc-tensor-creation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise\n",
    "Modify and execute this code to compute this expression: `a ** 2 + b ** 2 + 2 * a * b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.     2.  1026.]\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "a = theano.tensor.vector() # declare variable\n",
    "out = a + a ** 10               # build symbolic expression\n",
    "f = theano.function([a], out)   # compile function\n",
    "print(f([0, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 25.  49.  81.]\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "a = theano.tensor.vector() # declare variable\n",
    "b = theano.tensor.vector() # declare variable\n",
    "out = a ** 2 + b ** 2 + 2 * a * b            # build symbolic expression\n",
    "f = theano.function([a,b], out)   # compile function\n",
    "print(f([0, 1, 2], [5, 6, 7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression example.\n",
    "Using `T.exp` or `T.tanh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5       ,  0.73105858],\n",
       "       [ 0.26894142,  0.11920292]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.dmatrix('x')\n",
    "s = 1 / (1 + T.exp(-x))\n",
    "logistic = theano.function([x], s)\n",
    "logistic([[0, 1], [-1, -2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5       ,  0.73105858],\n",
       "       [ 0.26894142,  0.11920292]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = (1 + T.tanh(x / 2)) / 2\n",
    "logistic = theano.function([x], s2)\n",
    "logistic([[0, 1], [-1, -2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing More than one Thing at the Same Time\n",
    "Theano supports functions with multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.,  0.],\n",
      "       [-1., -2.]]), array([[ 1.,  0.],\n",
      "       [ 1.,  2.]]), array([[ 1.,  0.],\n",
      "       [ 1.,  4.]])]\n"
     ]
    }
   ],
   "source": [
    "a, b = T.dmatrices('a', 'b') # is like (matlab's) deal(T.dmatrix)\n",
    "diff = a - b\n",
    "abs_diff = abs(diff)\n",
    "diff_squared = diff**2\n",
    "f = theano.function([a, b], [diff, abs_diff, diff_squared])\n",
    "\n",
    "print f([[1, 1], [1, 1]], [[0, 1], [2, 3]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Value for an Argument\n",
    "`In` class allows you to specify properties of your function?s parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.0\n",
      "35.0\n"
     ]
    }
   ],
   "source": [
    "from theano import In ## <<-- NOTE THIS IMPORT.  \n",
    "from theano import function\n",
    "x, y = T.dscalars('x', 'y')\n",
    "z = x + y\n",
    "f = function([x, In(y, value=1)], z)\n",
    "print f(33)\n",
    "print f(33, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default vals can be also assigned by name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(33.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, w = T.dscalars('x', 'y', 'w')\n",
    "z = (x + y) * w\n",
    "f = function([x, In(y, value=1), In(w, value=2, name='w_by_name')], z)\n",
    "f(33, w_by_name=1, y=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Variables [(link)](http://deeplearning.net/software/theano/tutorial/examples.html#using-shared-variables)\n",
    "Used to make a function with an internal state. For example, an accumulator, or parameters (network weights) of a NN.\n",
    "\n",
    "It is **called a shared variable** because its **value is shared between many functions**.\n",
    "They *have an internal value* that defines the value taken by this symbolic variable in *all the functions* that use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano import shared ## <<-- NOTE THIS IMPORT.  \n",
    "state = shared(0)\n",
    "inc = T.iscalar('inc')\n",
    "accumulator = function([inc], state, updates=[(state, state+inc)]) ## Note updates =.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `updates` parameter of `function`\n",
    "`updates` must be supplied with **a list of pairs** of the form *(shared-variable, new expression)*. It **can also be a dictionary** whose keys are shared-variables and values are the new expressions\n",
    "\n",
    "\n",
    "It is possible to reset the state. With `.set_value()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "301\n",
      "-1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(state.get_value())\n",
    "print accumulator(1)\n",
    "print(state.get_value())\n",
    "print accumulator(300)\n",
    "print(state.get_value())\n",
    "state.set_value(-1)\n",
    "print accumulator(3)\n",
    "print(state.get_value())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "-2\n"
     ]
    }
   ],
   "source": [
    "# define more than one function to use the same shared variable. \n",
    "decrementor = function([inc], state, updates=[(state, state-inc)]) \n",
    "decrementor(2)\n",
    "print(state.get_value())\n",
    "decrementor(2)\n",
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `givens`: When expressed some formula using a `shared` variable, but you do not want to use its value.\n",
    "the `givens` is a mechanism that allows you to replace any part of your formula with a different expression that evaluates to a tensor of same shape and dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "-2\n",
      "7\n",
      "-2\n"
     ]
    }
   ],
   "source": [
    "fn_of_state = state * 2 + inc\n",
    "foo = T.scalar(dtype=state.dtype) # The type of foo must match the shared variable we are replacing with the ``givens``\n",
    "skip_shared = function([inc, foo], fn_of_state, givens=[(state, foo)]) # <<-- NOTE THIS\n",
    "print skip_shared(1, 3)\n",
    "print(state.get_value())\n",
    "print skip_shared(1, 3)\n",
    "print(state.get_value())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying functions:\n",
    "Creating similar functions but with different shared variables or updates.\n",
    "\n",
    "The `swap` parameter, which is a dictionary of shared variables to exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    }
   ],
   "source": [
    "new_state = theano.shared(34)\n",
    "new_accumulator = accumulator.copy(swap={state:new_state}) # <<-- NOTE THIS, and the swap dictionary\n",
    "new_accumulator(100)\n",
    "print(new_state.get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a copy with updates removed using the delete_updates parameter, which is set to False by default\n",
    "`null_accumulator = accumulator.copy(delete_updates=True)`\n",
    "It doesn't work. Looks like a [tutorial bug](https://stackoverflow.com/questions/37911325/theano-tutorial-unusedinputerror-theano-function). A workaround is implemented below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_accumulator = theano.function([inc], state,\n",
    "    updates=[(state, state+inc)], on_unused_input='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2\n",
      "8998\n"
     ]
    }
   ],
   "source": [
    "print null_accumulator(9000)\n",
    "print state.get_value() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Variables\n",
    "Putting randomness into Theano's computations **is to put random variables in your graph**. Theano will **allocate a NumPy RandomStream object** (a random number generator) for each such variable, and **draw from it as necessary**\n",
    "\n",
    "Other distribuitions are [here](http://deeplearning.net/software/theano/library/tensor/raw_random.html#libdoc-tensor-raw-random)\n",
    "\n",
    "There are 2 other implementations based on MRG31k3p and CURAND. **The RandomStream only work on the CPU**, MRG31k3p work on the CPU and GPU. CURAND only work on the GPU.\n",
    "#### Using MRG Version \n",
    "`from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.tensor.shared_randomstreams import RandomStreams # <<-- NOTE THIS\n",
    "from theano import function\n",
    "srng = RandomStreams(seed=234) # SEED all of the random variables allocated by a RandomStreams\n",
    "rv_u = srng.uniform((2,2)) # defining a RV \n",
    "rv_n = srng.normal((2,2)) # defining a RV \n",
    "f = function([], rv_u)\n",
    "g = function([], rv_n, no_default_updates=True)    #Not updating rv_n.rng\n",
    "nearly_zeros = function([], rv_u + rv_u - 2 * rv_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12672381  0.97091597]\n",
      " [ 0.13989098  0.88754825]]\n",
      "[[ 0.31971415  0.47584377]\n",
      " [ 0.24129163  0.42046081]]\n"
     ]
    }
   ],
   "source": [
    "print f()\n",
    "print f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we add the extra argument `no_default_updates=True` to function (as in g), then **the random number generator state is not affected** by calling the returned function. So, for example, **calling g multiple times will return the same numbers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.37328447 -0.65746672]\n",
      " [-0.36302373 -0.97484625]]\n",
      "[[ 0.37328447 -0.65746672]\n",
      " [-0.36302373 -0.97484625]]\n"
     ]
    }
   ],
   "source": [
    "print g()\n",
    "print g()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed just one random variable by seeding or assigning to the `.rng` attribute, using `.rng.set_value()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng_val = rv_u.rng.get_value(borrow=True) \n",
    "rng_val.seed(89234) \n",
    "rv_u.rng.set_value(rng_val, borrow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying Random State Between Theano Graphs\n",
    "for example if you are trying to initialize the state of a model, from the parameters of a pickled version of a previous model. This can be achieved by copying elements of the `state_updates` parameter.\n",
    "Example in [link](http://deeplearning.net/software/theano/tutorial/examples.html#copying-random-state-between-theano-graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression on MNIST example\n",
    "See [here](TF-Tut1@Theano.ipynb) doing the tensorflow tutorial on Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping (`scan` function)\n",
    "\n",
    "#### Solving issues with BLAS is [here](http://stackoverflow.com/questions/6789368/how-to-make-sure-the-numpy-blas-libraries-are-available-as-dynamically-loadable)\n",
    "\n",
    "#### Comments from the doc with Anna:\n",
    "Deals with building symbolic graphs over loops. The syntax is as follows:\n",
    "\n",
    "\n",
    "`[rval,updates] = theano.scan(fn *a func handler*, \n",
    " sequences=None *vectors where we iterate, sending a single element to iteration of scan*,\n",
    " outputs_info=None *list of initializations for previous rvals needed in an iteration*,\n",
    "non_sequences=None *non changing inputs per iteration*, \n",
    "n_steps=None *number of iterations*, \n",
    "name=None *name of iteration - usefull for debugging*)`\n",
    "\n",
    "in `fn` the func handler,  **the output of the prior call to fn** (or the initial value, initially) **is the first parameter**, *followed by inputs from all non-sequences.*\n",
    "\n",
    "The general order of function parameters to fn is:\n",
    "\n",
    "`sequences (if any), prior result(s) (if needed), non-sequences (if any)`\n",
    "\n",
    "\n",
    "If we need only part of the return values for the next iteration, we initialize outputs_info  properly with the needed values and insert [None] for every rval we don't need. The rval-s we don't need must be at the end. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for i in range(10):\n",
    "    k=k+1\n",
    "print k    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A counter and a range with theano scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6 7 8]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = T.iscalar('i')\n",
    "i0 = T.iscalar('i0')\n",
    "rval, _ = theano.scan(lambda xprev: xprev+1, outputs_info=[i0], n_steps=i)\n",
    "f_range = theano.function([i,i0], rval)\n",
    "f_last = theano.function([i,i0], rval[-1])\n",
    "print f_range(5,3)\n",
    "print f_last(6,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualization for the theano graph\n",
    "import theano.d3viz as d3v"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d3v.d3viz(rval, 'pics/rval_range.html')\n",
    "d3v.d3viz(f_range, 'pics/f_range.html')\n",
    "!firefox pics/f_range.html\n",
    "!firefox pics/rval_range.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A recurrence with scan: Fibonacci Series\n",
    "NOTE: on **`outputs_info`** we need to indicate the **`inital`** variable (`x0` here), and the arguments that will be passed to the function at each step. The key **`taps`** is a list of indices to the results to be used as arguments, -1 and -2 mean the last and penultimate entries. By default, taps is set to [-1]. ([ref](http://nbviewer.jupyter.org/gist/triangleinequality/1350873eebea33973e41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = T.iscalar('i')\n",
    "x0 = T.ivector('x0') ## <<-- NOTE: This is a VECTOR, with 2 elements for init the series\n",
    "rval, _ = theano.scan(lambda xn2, xn1: xn2+xn1, outputs_info=[{'initial':x0, 'taps':[-2,-1]}], n_steps=i)\n",
    "f_fibo = theano.function([i, x0], rval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([          1,           2,           3,           5,           8,\n",
       "                13,          21,          34,          55,          89,\n",
       "               144,         233,         377,         610,         987,\n",
       "              1597,        2584,        4181,        6765,       10946,\n",
       "             17711,       28657,       46368,       75025,      121393,\n",
       "            196418,      317811,      514229,      832040,     1346269,\n",
       "           2178309,     3524578,     5702887,     9227465,    14930352,\n",
       "          24157817,    39088169,    63245986,   102334155,   165580141,\n",
       "         267914296,   433494437,   701408733,  1134903170,  1836311903,\n",
       "       -1323752223,   512559680,  -811192543,  -298632863, -1109825406], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_fibo(50, np.asarray([0,1], dtype=np.int32)) ## NOTE OVERFLOW IN THE LAST RESULTS ENTRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"scan_4/TensorArrayPack:0\", shape=(6, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "i = T.iscalar('i')\n",
    "x0 = T.ivector('x0') ## <<-- NOTE: This is a VECTOR, with 2 elements for init the series\n",
    "elems = np.array([1, 0, 0, 0, 0, 0])\n",
    "# rval, _ = theano.scan(lambda e,x: (x[1], x[0]+x[1]), sequences=elems, outputs_info=[(np.array(0), np.array(1))])\n",
    "# f_fibo = theano.function([i, x0], rval)\n",
    "\n",
    "initializer = (np.array(0), np.array(1))\n",
    "fibonaccis = tf.scan(lambda a, _: (a[1], a[0] + a[1]), elems, initializer)\n",
    "print fibonaccis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding flow control to scan  loops  ([ref](http://nbviewer.jupyter.org/gist/triangleinequality/1350873eebea33973e41))\n",
    "we can end early if a condition is met, like say overflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([         1,          2,          3,          5,          8,\n",
       "               13,         21,         34,         55,         89,\n",
       "              144,        233,        377,        610,        987,\n",
       "             1597,       2584,       4181,       6765,      10946,\n",
       "            17711,      28657,      46368,      75025,     121393,\n",
       "           196418,     317811,     514229,     832040,    1346269,\n",
       "          2178309,    3524578,    5702887,    9227465,   14930352,\n",
       "         24157817,   39088169,   63245986,  102334155,  165580141,\n",
       "        267914296,  433494437,  701408733, 1134903170, 1836311903], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fib(f_m_1, f_m_2):\n",
    "    ret= f_m_1+ f_m_2\n",
    "    next_ret = ret+f_m_1\n",
    "    return ret, theano.scan_module.until(next_ret <0) ## NOTE THE 2nd TERM for Stopping condition\n",
    "i = T.iscalar('i')\n",
    "x0 = T.ivector('x0') \n",
    "rval, _ = theano.scan(fib, outputs_info=[{'initial':x0, 'taps':[-2,-1]}], n_steps=i)\n",
    "f_fibo = theano.function([i, x0], rval)\n",
    "\n",
    "f_fibo(50, np.asarray([0,1], dtype=np.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over vectors/matrices/tensors\n",
    "By passing `scan` a **`sequences`** argument, the object we would like to iterate over. NOTE: It iterates over the first dimension of the tensor: For a vector, over the entries. For a matrix, over the rows...\n",
    "#### NOTE about fn arguments order\n",
    "The general order of function parameters to fn is:\n",
    "\n",
    "`sequences (if any), prior result(s) (if needed), non-sequences (if any)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   2.   5.  10.  21.  12.]\n",
      "[  1.   2.   5.  10.  21.  12.]\n"
     ]
    }
   ],
   "source": [
    "x = T.fvector('x')\n",
    "rval, _ = theano.scan(fn=lambda xi, cprev: cprev+xi, outputs_info=0.0, sequences=x)\n",
    "f_cumsum = theano.function([x], rval)\n",
    "X=np.asarray([1,1,3,5,11,-9], dtype=np.float32)\n",
    "print f_cumsum(X)\n",
    "print rval.eval({x:X})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using shared variables with `scan`\n",
    "[link with gibbs sampling](http://deeplearning.net/software/theano/library/scan.html#using-shared-variables-gibbs-sampling)\n",
    "\n",
    "**Highlights**\n",
    "* `updates` dictionary links a shared variable with its updated value after k steps.\n",
    "*  if we use shared variables but we do not iterate over them you do not need to pass them as arguments. **However, passing them to the scan function is a good practice**, which results in a simpler computational graph, which **speeds up the optimization and the execution**. \n",
    "* To pass the shared variables to `scan` you need to put them in a list as input to `non_sequences` argument\n",
    "* Using the **`strict` flag**: With `strict=True` ,scan assumes that all the necessary shared variables in fn are passed as a part of `non_sequences`. This has to be ensured by the user. Otherwise, it will result in an error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN example with `scan`\n",
    "The RNN function is:\n",
    "\n",
    "![caption](http://deeplearning.net/software/theano/_images/math/f319ccb886e8ddd6d3f4ff4dc8895d6fddacf054.png)\n",
    "This is a useless RNN, just used for demo\n",
    "\n",
    "'u' is a sequence over which we need to iterate on, `x` and `y` are two outputs\n",
    "\n",
    "* For scan is crucial only for the variables representing the different time taps to be in the same order as the one in which these taps are given. Also, not only taps should respect an order, but also variables, since this is how scan figures out what should be represented by what.\n",
    "\n",
    "some more details are [here](http://deeplearning.net/software/theano/library/scan.html#multiple-outputs-several-taps-values-recurrent-neural-network-with-scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NOTE in function def, first vars are vars we seq on (u), then the state vars (x,y). \n",
    "# Convention here (not a must) is to have first the earlier time stamps (e.g. x_tm3 before x_tm1)\n",
    "def oneStep(u_tm4, u_t, x_tm3, x_tm1, y_tm1, W, W_in_1, W_in_2, W_feedback, W_out): \n",
    "    ## NOTE          vvvv    We do the dot product in the opposite direction, since we seq. on row vectors\n",
    "    x_t = T.tanh(T.dot(x_tm1, W) + \\\n",
    "                 T.dot(u_t,   W_in_1) + \\\n",
    "                 T.dot(u_tm4, W_in_2) + \\\n",
    "                 T.dot(y_tm1, W_feedback))\n",
    "    y_t = T.dot(x_tm3, W_out)\n",
    "    return x_t, y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = T.matrix('W')\n",
    "W_in_1 = T.matrix('W_in_1')\n",
    "W_in_2 = T.matrix('W_in_2')\n",
    "W_feedback = T.matrix('W_feedback')\n",
    "W_out = T.matrix('W_out')\n",
    "\n",
    "u = T.matrix('u') # input as  sequence of (row) vectors\n",
    "## Initial state for x0 and y0\n",
    "x0 = T.matrix('x0') # initial state of x has to be a matrix, since\n",
    "                # it has to cover x[-3]\n",
    "y0 = T.vector('y0') # y0 is just a vector since scan has only to provide\n",
    "                # y[-1]\n",
    "\n",
    "([x_vals, y_vals], updates) = theano.scan(fn=oneStep, \n",
    "                                          sequences={'input':u, 'taps':[-4,0]},   # <<-- NOTE THIS\n",
    "                                          outputs_info=[{'initial':x0, 'taps':[-3,-1]}, y0],  # <<-- NOTE THIS\n",
    "                                          non_sequences=[W, W_in_1, W_in_2, W_feedback, W_out],\n",
    "                                          strict=True) \n",
    " # for second input y, scan adds -1 in output_taps by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d3v.d3viz(x_vals, 'pics/x_vals.html')\n",
    "!firefox pics/x_vals.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
